"""
enhanced_realtime_twse_fetcher.py - æ•´åˆTWSEå³æ™‚APIçš„å¢å¼·ç‰ˆå°è‚¡æ•¸æ“šæŠ“å–å™¨
æ”¯æ´ç›¤ä¸­å³æ™‚æ•¸æ“šç²å–ï¼Œæé«˜ç›¤ä¸­åˆ†ææº–ç¢ºç‡
"""
import os
import json
import time
import requests
import pandas as pd
import pytz
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
import logging
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
import asyncio
# å¯é¸çš„ aiohttp æ”¯æ´
try:
    import aiohttp
    AIOHTTP_AVAILABLE = True
except ImportError:
    AIOHTTP_AVAILABLE = False
    # å‰µå»ºæ¨¡æ“¬çš„ aiohttp é¡é¿å…éŒ¯èª¤
    class aiohttp:
        class ClientSession:
            def __init__(self, *args, **kwargs): pass
        class ClientTimeout:
            def __init__(self, *args, **kwargs): pass
from dataclasses import dataclass
from collections import deque
import random

# é…ç½®æ—¥èªŒ
logger = logging.getLogger(__name__)

@dataclass
class RealtimeAPIConfig:
    """å³æ™‚APIé…ç½®"""
    base_url: str = "https://mis.twse.com.tw/stock/api/getStockInfo.jsp"
    max_stocks_per_request: int = 50  # æ¯æ¬¡è«‹æ±‚æœ€å¤šè‚¡ç¥¨æ•¸
    max_requests_per_minute: int = 30  # æ¯åˆ†é˜æœ€å¤šè«‹æ±‚æ¬¡æ•¸
    request_interval: float = 2.0  # è«‹æ±‚é–“éš”ï¼ˆç§’ï¼‰
    timeout: int = 10  # è«‹æ±‚è¶…æ™‚æ™‚é–“
    retry_attempts: int = 3  # é‡è©¦æ¬¡æ•¸
    backoff_factor: float = 1.5  # é€€é¿å› å­
    cooldown_period: int = 60  # è¢«å°é–å¾Œçš„å†·å»æœŸï¼ˆç§’ï¼‰

class RateLimiter:
    """APIè«‹æ±‚é »ç‡é™åˆ¶å™¨"""
    
    def __init__(self, max_requests: int, time_window: int):
        self.max_requests = max_requests
        self.time_window = time_window
        self.requests = deque()
        self.lock = threading.Lock()
        self.blocked_until = 0
    
    def can_request(self) -> bool:
        """æª¢æŸ¥æ˜¯å¦å¯ä»¥ç™¼èµ·è«‹æ±‚"""
        with self.lock:
            current_time = time.time()
            
            # æª¢æŸ¥æ˜¯å¦åœ¨å†·å»æœŸ
            if current_time < self.blocked_until:
                return False
            
            # æ¸…ç†éæœŸçš„è«‹æ±‚è¨˜éŒ„
            while self.requests and (current_time - self.requests[0]) > self.time_window:
                self.requests.popleft()
            
            # æª¢æŸ¥æ˜¯å¦è¶…éé™åˆ¶
            return len(self.requests) < self.max_requests
    
    def record_request(self) -> None:
        """è¨˜éŒ„ä¸€æ¬¡è«‹æ±‚"""
        with self.lock:
            self.requests.append(time.time())
    
    def set_blocked(self, duration: int) -> None:
        """è¨­ç½®è¢«å°é–ç‹€æ…‹"""
        with self.lock:
            self.blocked_until = time.time() + duration
            logger.warning(f"APIè¢«å°é–ï¼Œå†·å»æœŸ {duration} ç§’")

class EnhancedRealtimeTWSEFetcher:
    """å¢å¼·ç‰ˆå³æ™‚å°è‚¡æ•¸æ“šæŠ“å–å™¨"""
    
    def __init__(self, cache_dir: str = 'cache'):
        """åˆå§‹åŒ–"""
        self.cache_dir = cache_dir
        os.makedirs(cache_dir, exist_ok=True)
        
        # å°ç£æ™‚å€
        self.taipei_tz = pytz.timezone('Asia/Taipei')
        
        # å³æ™‚APIé…ç½®
        self.realtime_config = RealtimeAPIConfig()
        
        # é »ç‡é™åˆ¶å™¨
        self.rate_limiter = RateLimiter(
            max_requests=self.realtime_config.max_requests_per_minute,
            time_window=60
        )
        
        # è«‹æ±‚æ¨™é ­
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Accept': 'application/json, text/javascript, */*; q=0.01',
            'Accept-Language': 'zh-TW,zh;q=0.9,en;q=0.8',
            'Referer': 'https://mis.twse.com.tw/',
            'X-Requested-With': 'XMLHttpRequest'
        }
        
        # å¾åŸæœ‰ç³»çµ±ç¹¼æ‰¿åŸºç¤åŠŸèƒ½
        from twse_data_fetcher import TWStockDataFetcher
        self.base_fetcher = TWStockDataFetcher(cache_dir)
        
        # å³æ™‚æ•¸æ“šå¿«å–
        self.realtime_cache = {}
        self.cache_expiry = 30  # å³æ™‚æ•¸æ“šå¿«å–30ç§’
        
        # çµ±è¨ˆè³‡è¨Š
        self.stats = {
            'realtime_requests': 0,
            'realtime_success': 0,
            'realtime_failures': 0,
            'cache_hits': 0,
            'api_blocks': 0,
            'fallback_used': 0
        }
    
    def get_current_taiwan_time(self) -> datetime:
        """ç²å–ç•¶å‰å°ç£æ™‚é–“"""
        return datetime.now(self.taipei_tz)
    
    def is_trading_hours(self) -> bool:
        """æª¢æŸ¥æ˜¯å¦ç‚ºäº¤æ˜“æ™‚é–“"""
        now = self.get_current_taiwan_time()
        hour_decimal = now.hour + now.minute / 60.0
        weekday = now.weekday()
        
        # åªæœ‰å·¥ä½œæ—¥çš„äº¤æ˜“æ™‚é–“
        if weekday >= 5:  # é€±æœ«
            return False
        
        # 9:00-12:00 å’Œ 13:00-13:30
        return (9.0 <= hour_decimal < 12.0) or (13.0 <= hour_decimal < 13.5)
    
    def should_use_realtime_api(self) -> bool:
        """åˆ¤æ–·æ˜¯å¦æ‡‰è©²ä½¿ç”¨å³æ™‚API"""
        return self.is_trading_hours() and self.rate_limiter.can_request()
    
    def build_realtime_url(self, stock_codes: List[str]) -> str:
        """
        æ§‹å»ºå³æ™‚API URL
        
        åƒæ•¸:
        - stock_codes: è‚¡ç¥¨ä»£ç¢¼åˆ—è¡¨
        
        è¿”å›:
        - å®Œæ•´çš„API URL
        """
        # é™åˆ¶æ¯æ¬¡æŸ¥è©¢çš„è‚¡ç¥¨æ•¸é‡
        limited_codes = stock_codes[:self.realtime_config.max_stocks_per_request]
        
        # æ§‹å»ºex_chåƒæ•¸
        ex_ch_parts = []
        for code in limited_codes:
            # åˆ¤æ–·æ˜¯ä¸Šå¸‚é‚„æ˜¯ä¸Šæ«ƒ
            if code.startswith(('1', '2', '3', '4', '5', '6', '9')):
                # ä¸Šå¸‚è‚¡ç¥¨
                ex_ch_parts.append(f"tse_{code}.tw")
            else:
                # ä¸Šæ«ƒè‚¡ç¥¨ï¼ˆæš«æ™‚ä¹Ÿç”¨tseï¼Œå¯¦éš›å¯èƒ½éœ€è¦èª¿æ•´ï¼‰
                ex_ch_parts.append(f"otc_{code}.tw")
        
        ex_ch_param = "|".join(ex_ch_parts)
        
        return f"{self.realtime_config.base_url}?ex_ch={ex_ch_param}"
    
    async def fetch_realtime_data_async(self, stock_codes: List[str]) -> List[Dict[str, Any]]:
        """
        ç•°æ­¥ç²å–å³æ™‚æ•¸æ“š
        
        åƒæ•¸:
        - stock_codes: è‚¡ç¥¨ä»£ç¢¼åˆ—è¡¨
        
        è¿”å›:
        - å³æ™‚è‚¡ç¥¨æ•¸æ“šåˆ—è¡¨
        """
        if not self.should_use_realtime_api():
            logger.info("ä¸æ»¿è¶³å³æ™‚APIä½¿ç”¨æ¢ä»¶ï¼Œä½¿ç”¨åŸºç¤æ•¸æ“š")
            self.stats['fallback_used'] += 1
            return await self._fallback_to_base_data(stock_codes)
        
        # åˆ†æ‰¹è™•ç†è‚¡ç¥¨
        all_stocks = []
        batch_size = self.realtime_config.max_stocks_per_request
        
        async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=self.realtime_config.timeout)) as session:
            for i in range(0, len(stock_codes), batch_size):
                batch_codes = stock_codes[i:i + batch_size]
                
                try:
                    # æª¢æŸ¥é »ç‡é™åˆ¶
                    if not self.rate_limiter.can_request():
                        logger.warning("APIé »ç‡é™åˆ¶ï¼Œç­‰å¾…...")
                        await asyncio.sleep(self.realtime_config.request_interval)
                        continue
                    
                    # æ§‹å»ºURL
                    url = self.build_realtime_url(batch_codes)
                    
                    # è¨˜éŒ„è«‹æ±‚
                    self.rate_limiter.record_request()
                    self.stats['realtime_requests'] += 1
                    
                    logger.debug(f"è«‹æ±‚å³æ™‚æ•¸æ“š: {len(batch_codes)} æ”¯è‚¡ç¥¨")
                    
                    # ç™¼èµ·è«‹æ±‚
                    async with session.get(url, headers=self.headers) as response:
                        if response.status == 200:
                            data = await response.json()
                            batch_stocks = self._parse_realtime_response(data, batch_codes)
                            all_stocks.extend(batch_stocks)
                            self.stats['realtime_success'] += 1
                            
                            logger.info(f"æˆåŠŸç²å– {len(batch_stocks)} æ”¯è‚¡ç¥¨å³æ™‚æ•¸æ“š")
                        else:
                            logger.error(f"å³æ™‚APIè«‹æ±‚å¤±æ•—: HTTP {response.status}")
                            self._handle_api_error(response.status)
                
                except Exception as e:
                    logger.error(f"ç²å–å³æ™‚æ•¸æ“šå¤±æ•—: {e}")
                    self.stats['realtime_failures'] += 1
                
                # æ‰¹æ¬¡é–“å»¶é²
                if i + batch_size < len(stock_codes):
                    await asyncio.sleep(self.realtime_config.request_interval)
        
        return all_stocks
    
    def fetch_realtime_data_sync(self, stock_codes: List[str]) -> List[Dict[str, Any]]:
        """
        åŒæ­¥ç²å–å³æ™‚æ•¸æ“šï¼ˆåŒ…è£ç•°æ­¥æ–¹æ³•ï¼‰
        
        åƒæ•¸:
        - stock_codes: è‚¡ç¥¨ä»£ç¢¼åˆ—è¡¨
        
        è¿”å›:
        - å³æ™‚è‚¡ç¥¨æ•¸æ“šåˆ—è¡¨
        """
        try:
            # å˜—è©¦ç²å–ç¾æœ‰çš„äº‹ä»¶å¾ªç’°
            loop = asyncio.get_event_loop()
            if loop.is_running():
                # å¦‚æœäº‹ä»¶å¾ªç’°æ­£åœ¨é‹è¡Œï¼Œå‰µå»ºä»»å‹™
                future = asyncio.ensure_future(self.fetch_realtime_data_async(stock_codes))
                return []  # æš«æ™‚è¿”å›ç©ºåˆ—è¡¨ï¼Œå¯¦éš›æ‡‰è©²ä½¿ç”¨å…¶ä»–æ–¹å¼è™•ç†
            else:
                # å¦‚æœæ²’æœ‰é‹è¡Œçš„äº‹ä»¶å¾ªç’°ï¼Œç›´æ¥é‹è¡Œ
                return loop.run_until_complete(self.fetch_realtime_data_async(stock_codes))
        except RuntimeError:
            # æ²’æœ‰äº‹ä»¶å¾ªç’°ï¼Œå‰µå»ºæ–°çš„
            return asyncio.run(self.fetch_realtime_data_async(stock_codes))
    
    def _parse_realtime_response(self, response_data: Dict, requested_codes: List[str]) -> List[Dict[str, Any]]:
        """
        è§£æå³æ™‚APIå›æ‡‰æ•¸æ“š
        
        åƒæ•¸:
        - response_data: APIå›æ‡‰æ•¸æ“š
        - requested_codes: è«‹æ±‚çš„è‚¡ç¥¨ä»£ç¢¼åˆ—è¡¨
        
        è¿”å›:
        - è§£æå¾Œçš„è‚¡ç¥¨æ•¸æ“šåˆ—è¡¨
        """
        stocks = []
        
        try:
            # TWSEå³æ™‚APIå›æ‡‰æ ¼å¼
            if 'msgArray' in response_data:
                for item in response_data['msgArray']:
                    stock_data = self._parse_single_realtime_stock(item)
                    if stock_data:
                        stocks.append(stock_data)
            
            # æ›´æ–°å¿«å–
            for stock in stocks:
                cache_key = f"realtime_{stock['code']}"
                self.realtime_cache[cache_key] = {
                    'data': stock,
                    'timestamp': time.time()
                }
                self.stats['cache_hits'] += 1
            
        except Exception as e:
            logger.error(f"è§£æå³æ™‚æ•¸æ“šå¤±æ•—: {e}")
        
        return stocks
    
    def _parse_single_realtime_stock(self, item: Dict) -> Optional[Dict[str, Any]]:
        """è§£æå–®æ”¯è‚¡ç¥¨çš„å³æ™‚æ•¸æ“š"""
        try:
            # TWSEå³æ™‚APIå­—æ®µæ˜ å°„
            code = item.get('c', '').strip()
            name = item.get('n', '').strip()
            
            if not code or not name:
                return None
            
            # åƒ¹æ ¼è³‡è¨Š
            current_price = float(item.get('z', '0') or '0')  # æˆäº¤åƒ¹
            open_price = float(item.get('o', '0') or '0')     # é–‹ç›¤åƒ¹
            high_price = float(item.get('h', '0') or '0')     # æœ€é«˜åƒ¹
            low_price = float(item.get('l', '0') or '0')      # æœ€ä½åƒ¹
            
            # æˆäº¤é‡å’Œé‡‘é¡
            volume = int(item.get('v', '0') or '0')           # æˆäº¤é‡
            trade_value = current_price * volume              # æˆäº¤é‡‘é¡
            
            # æ¼²è·Œè³‡è¨Š
            change = float(item.get('u', '0') or '0')         # æ¼²è·Œ
            if change == 0:
                change = float(item.get('d', '0') or '0') * -1  # å¦‚æœæ²’æœ‰æ¼²ï¼Œæª¢æŸ¥è·Œ
            
            yesterday_close = current_price - change
            change_percent = (change / yesterday_close * 100) if yesterday_close > 0 else 0
            
            # æ™‚é–“æˆ³
            timestamp = item.get('t', '')  # æ™‚é–“æˆ³
            
            return {
                "code": code,
                "name": name,
                "market": "TWSE",
                "open": open_price,
                "high": high_price,
                "low": low_price,
                "close": current_price,
                "volume": volume,
                "trade_value": trade_value,
                "change": change,
                "change_percent": round(change_percent, 2),
                "timestamp": timestamp,
                "date": self.get_current_taiwan_time().strftime('%Y-%m-%d'),
                "data_source": "TWSE_REALTIME_API",
                "fetch_time": datetime.now().isoformat(),
                "is_realtime": True,
                "data_accuracy": "high",
                "data_freshness": "å³æ™‚æ•¸æ“š"
            }
            
        except Exception as e:
            logger.error(f"è§£æå–®æ”¯è‚¡ç¥¨å³æ™‚æ•¸æ“šå¤±æ•—: {e}")
            return None
    
    def _handle_api_error(self, status_code: int) -> None:
        """è™•ç†APIéŒ¯èª¤"""
        if status_code == 429:  # Too Many Requests
            self.stats['api_blocks'] += 1
            self.rate_limiter.set_blocked(self.realtime_config.cooldown_period)
            logger.warning("APIé »ç‡é™åˆ¶è§¸ç™¼ï¼Œé€²å…¥å†·å»æœŸ")
        elif status_code >= 500:
            logger.error(f"æœå‹™å™¨éŒ¯èª¤: {status_code}")
        else:
            logger.warning(f"APIè«‹æ±‚å¤±æ•—: {status_code}")
    
    async def _fallback_to_base_data(self, stock_codes: List[str]) -> List[Dict[str, Any]]:
        """å›é€€åˆ°åŸºç¤æ•¸æ“š"""
        logger.info("ä½¿ç”¨åŸºç¤æ•¸æ“šä½œç‚ºå³æ™‚æ•¸æ“šçš„å›é€€")
        
        # ä½¿ç”¨åŸºç¤æŠ“å–å™¨ç²å–æ•¸æ“š
        all_stocks = self.base_fetcher.get_all_stocks_by_volume()
        
        # ç¯©é¸è«‹æ±‚çš„è‚¡ç¥¨
        requested_stocks = []
        code_set = set(stock_codes)
        
        for stock in all_stocks:
            if stock['code'] in code_set:
                # æ¨™è¨˜ç‚ºéå³æ™‚æ•¸æ“š
                stock['is_realtime'] = False
                stock['data_source'] = 'FALLBACK_DAILY'
                stock['data_freshness'] = 'æ—¥ç·šæ•¸æ“š'
                requested_stocks.append(stock)
        
        return requested_stocks
    
    def get_enhanced_stocks_by_time_slot(self, time_slot: str, date: str = None) -> List[Dict[str, Any]]:
        """
        å¢å¼·ç‰ˆæŒ‰æ™‚æ®µç²å–è‚¡ç¥¨ï¼ˆæ•´åˆå³æ™‚æ•¸æ“šï¼‰
        
        åƒæ•¸:
        - time_slot: æ™‚æ®µåç¨±
        - date: æŒ‡å®šæ—¥æœŸ
        
        è¿”å›:
        - å¢å¼·çš„è‚¡ç¥¨æ•¸æ“šåˆ—è¡¨
        """
        logger.info(f"ç²å– {time_slot} æ™‚æ®µçš„å¢å¼·ç‰ˆè‚¡ç¥¨æ•¸æ“š")
        
        # å…ˆç²å–åŸºç¤æ•¸æ“š
        base_stocks = self.base_fetcher.get_stocks_by_time_slot(time_slot, date)
        
        # å¦‚æœä¸æ˜¯äº¤æ˜“æ™‚é–“ï¼Œç›´æ¥è¿”å›åŸºç¤æ•¸æ“š
        if not self.is_trading_hours():
            logger.info("éäº¤æ˜“æ™‚é–“ï¼Œä½¿ç”¨åŸºç¤æ•¸æ“š")
            return base_stocks
        
        # æå–å‰Næ”¯æ´»èºè‚¡ç¥¨çš„ä»£ç¢¼ç”¨æ–¼å³æ™‚æ›´æ–°
        top_count = min(len(base_stocks), 200)  # é™åˆ¶å³æ™‚æŸ¥è©¢æ•¸é‡
        top_codes = [stock['code'] for stock in base_stocks[:top_count]]
        
        logger.info(f"å˜—è©¦ç²å–å‰ {len(top_codes)} æ”¯è‚¡ç¥¨çš„å³æ™‚æ•¸æ“š")
        
        # ç²å–å³æ™‚æ•¸æ“š
        realtime_stocks = self.fetch_realtime_data_sync(top_codes)
        
        # å»ºç«‹å³æ™‚æ•¸æ“šæ˜ å°„
        realtime_map = {stock['code']: stock for stock in realtime_stocks}
        
        # åˆä½µæ•¸æ“šï¼šå„ªå…ˆä½¿ç”¨å³æ™‚æ•¸æ“š
        enhanced_stocks = []
        realtime_count = 0
        
        for base_stock in base_stocks:
            code = base_stock['code']
            
            if code in realtime_map:
                # ä½¿ç”¨å³æ™‚æ•¸æ“š
                enhanced_stock = realtime_map[code]
                # ä¿ç•™åŸºç¤æ•¸æ“šä¸­çš„ä¸€äº›é¡å¤–å­—æ®µ
                enhanced_stock['time_slot'] = base_stock.get('time_slot', time_slot)
                enhanced_stock['market_status'] = base_stock.get('market_status', 'trading')
                enhanced_stocks.append(enhanced_stock)
                realtime_count += 1
            else:
                # ä½¿ç”¨åŸºç¤æ•¸æ“š
                base_stock['is_realtime'] = False
                enhanced_stocks.append(base_stock)
        
        logger.info(f"æˆåŠŸæ•´åˆæ•¸æ“š: {realtime_count} æ”¯å³æ™‚, {len(enhanced_stocks)-realtime_count} æ”¯åŸºç¤")
        
        return enhanced_stocks
    
    def get_priority_stocks_realtime(self, priority_codes: List[str]) -> List[Dict[str, Any]]:
        """
        ç²å–å„ªå…ˆè‚¡ç¥¨çš„å³æ™‚æ•¸æ“šï¼ˆç”¨æ–¼é‡é»é—œæ³¨è‚¡ç¥¨ï¼‰
        
        åƒæ•¸:
        - priority_codes: å„ªå…ˆè‚¡ç¥¨ä»£ç¢¼åˆ—è¡¨
        
        è¿”å›:
        - å„ªå…ˆè‚¡ç¥¨çš„å³æ™‚æ•¸æ“š
        """
        logger.info(f"ç²å– {len(priority_codes)} æ”¯å„ªå…ˆè‚¡ç¥¨çš„å³æ™‚æ•¸æ“š")
        
        # æª¢æŸ¥å¿«å–
        cached_stocks = []
        uncached_codes = []
        current_time = time.time()
        
        for code in priority_codes:
            cache_key = f"realtime_{code}"
            if cache_key in self.realtime_cache:
                cache_item = self.realtime_cache[cache_key]
                if (current_time - cache_item['timestamp']) < self.cache_expiry:
                    cached_stocks.append(cache_item['data'])
                    continue
            uncached_codes.append(code)
        
        logger.info(f"å¿«å–å‘½ä¸­: {len(cached_stocks)} æ”¯, éœ€è¦æ›´æ–°: {len(uncached_codes)} æ”¯")
        
        # ç²å–æœªå¿«å–çš„æ•¸æ“š
        new_stocks = []
        if uncached_codes:
            new_stocks = self.fetch_realtime_data_sync(uncached_codes)
        
        # åˆä½µçµæœ
        all_stocks = cached_stocks + new_stocks
        
        # æŒ‰ä»£ç¢¼é †åºæ’åº
        code_order = {code: i for i, code in enumerate(priority_codes)}
        all_stocks.sort(key=lambda x: code_order.get(x['code'], 999))
        
        return all_stocks
    
    def get_stats(self) -> Dict[str, Any]:
        """ç²å–çµ±è¨ˆè³‡è¨Š"""
        total_requests = self.stats['realtime_requests']
        success_rate = (self.stats['realtime_success'] / total_requests * 100) if total_requests > 0 else 0
        
        return {
            **self.stats,
            'success_rate': round(success_rate, 2),
            'current_time': self.get_current_taiwan_time().strftime('%Y-%m-%d %H:%M:%S'),
            'is_trading_hours': self.is_trading_hours(),
            'can_use_realtime': self.should_use_realtime_api(),
            'rate_limit_status': {
                'requests_in_window': len(self.rate_limiter.requests),
                'max_requests': self.rate_limiter.max_requests,
                'blocked_until': self.rate_limiter.blocked_until,
                'is_blocked': time.time() < self.rate_limiter.blocked_until
            }
        }
    
    def cleanup_cache(self) -> None:
        """æ¸…ç†éæœŸçš„å³æ™‚æ•¸æ“šå¿«å–"""
        current_time = time.time()
        expired_keys = []
        
        for key, cache_item in self.realtime_cache.items():
            if (current_time - cache_item['timestamp']) > self.cache_expiry:
                expired_keys.append(key)
        
        for key in expired_keys:
            del self.realtime_cache[key]
        
        if expired_keys:
            logger.debug(f"æ¸…ç†äº† {len(expired_keys)} å€‹éæœŸçš„å³æ™‚æ•¸æ“šå¿«å–")

# ä½¿ç”¨ç¯„ä¾‹å’Œæ¸¬è©¦
if __name__ == "__main__":
    import asyncio
    
    # è¨­ç½®æ—¥èªŒ
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    print("ğŸš€ å¢å¼·ç‰ˆå³æ™‚å°è‚¡æ•¸æ“šæŠ“å–å™¨æ¸¬è©¦")
    print("=" * 60)
    
    # å‰µå»ºæŠ“å–å™¨
    fetcher = EnhancedRealtimeTWSEFetcher()
    
    # é¡¯ç¤ºç•¶å‰ç‹€æ…‹
    print("ğŸ“Š ç•¶å‰ç‹€æ…‹:")
    print(f"å°ç£æ™‚é–“: {fetcher.get_current_taiwan_time().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"äº¤æ˜“æ™‚é–“: {'æ˜¯' if fetcher.is_trading_hours() else 'å¦'}")
    print(f"å¯ç”¨å³æ™‚API: {'æ˜¯' if fetcher.should_use_realtime_api() else 'å¦'}")
    
    # æ¸¬è©¦å„ªå…ˆè‚¡ç¥¨å³æ™‚æ•¸æ“š
    print("\nğŸ” æ¸¬è©¦å„ªå…ˆè‚¡ç¥¨å³æ™‚æ•¸æ“š...")
    priority_codes = ['2330', '2317', '2454', '2412', '1301']  # å°ç©é›»ã€é´»æµ·ã€è¯ç™¼ç§‘ã€ä¸­è¯é›»ã€å°å¡‘
    
    start_time = time.time()
    realtime_stocks = fetcher.get_priority_stocks_realtime(priority_codes)
    fetch_time = time.time() - start_time
    
    print(f"ğŸ“ˆ å³æ™‚æ•¸æ“šçµæœ:")
    print(f"æŸ¥è©¢è€—æ™‚: {fetch_time:.2f} ç§’")
    print(f"ç²å–è‚¡ç¥¨: {len(realtime_stocks)} æ”¯")
    
    for stock in realtime_stocks:
        accuracy_icon = "ğŸ”´" if stock.get('is_realtime') else "âšª"
        print(f"  {accuracy_icon} {stock['code']} {stock['name']}")
        print(f"     ç¾åƒ¹: {stock['close']:.2f} | æ¼²è·Œ: {stock['change_percent']:+.2f}%")
        print(f"     æˆäº¤é¡: {stock['trade_value']:,.0f} å…ƒ")
        print(f"     æ•¸æ“šé¡å‹: {stock.get('data_freshness', 'æœªçŸ¥')}")
    
    # é¡¯ç¤ºçµ±è¨ˆè³‡è¨Š
    stats = fetcher.get_stats()
    print(f"\nğŸ“Š APIä½¿ç”¨çµ±è¨ˆ:")
    print(f"å³æ™‚è«‹æ±‚: {stats['realtime_requests']} æ¬¡")
    print(f"æˆåŠŸç‡: {stats['success_rate']:.1f}%")
    print(f"å¿«å–å‘½ä¸­: {stats['cache_hits']} æ¬¡")
    print(f"å›é€€ä½¿ç”¨: {stats['fallback_used']} æ¬¡")
    
    rate_status = stats['rate_limit_status']
    print(f"é »ç‡é™åˆ¶: {rate_status['requests_in_window']}/{rate_status['max_requests']}")
    
    # æ¸¬è©¦æ™‚æ®µæ•¸æ“š
    print(f"\nğŸ“Š æ¸¬è©¦æ™‚æ®µæ•¸æ“šç²å–...")
    enhanced_stocks = fetcher.get_enhanced_stocks_by_time_slot('morning_scan')
    
    realtime_count = sum(1 for s in enhanced_stocks if s.get('is_realtime'))
    print(f"æ™‚æ®µæ•¸æ“š: ç¸½è¨ˆ {len(enhanced_stocks)} æ”¯")
    print(f"å…¶ä¸­å³æ™‚: {realtime_count} æ”¯")
    print(f"åŸºç¤æ•¸æ“š: {len(enhanced_stocks) - realtime_count} æ”¯")
    
    print(f"\nâœ… å³æ™‚APIæ•´åˆå®Œæˆï¼")
    print(f"ğŸ¯ ä¸»è¦å„ªå‹¢:")
    print(f"  ğŸ“¡ ç›¤ä¸­å³æ™‚æ•¸æ“šæ›´æ–°ï¼ˆ30ç§’å¿«å–ï¼‰")
    print(f"  ğŸš¦ æ™ºèƒ½é »ç‡é™åˆ¶ï¼ˆæ¯åˆ†é˜æœ€å¤š30æ¬¡è«‹æ±‚ï¼‰")
    print(f"  ğŸ”„ è‡ªå‹•å›é€€æ©Ÿåˆ¶ï¼ˆAPIç•°å¸¸æ™‚ä½¿ç”¨åŸºç¤æ•¸æ“šï¼‰")
    print(f"  âš¡ æ‰¹é‡æŸ¥è©¢å„ªåŒ–ï¼ˆæ¯æ¬¡æœ€å¤š50æ”¯è‚¡ç¥¨ï¼‰")
    print(f"  ğŸ›¡ï¸ é˜²å°é–ä¿è­·ï¼ˆå†·å»æœŸå’Œé‡è©¦æ©Ÿåˆ¶ï¼‰")
    print(f"  ğŸ“Š è©³ç´°çµ±è¨ˆç›£æ§ï¼ˆæˆåŠŸç‡ã€å¿«å–å‘½ä¸­ç‡ç­‰ï¼‰")
