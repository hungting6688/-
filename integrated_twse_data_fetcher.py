#!/usr/bin/env python3
"""
integrated_twse_data_fetcher.py - æ•´åˆç‰ˆå°è‚¡æ•¸æ“šç²å–å™¨
çµåˆå¤šå€‹æ•¸æ“šæºå’ŒåŠŸèƒ½çš„å®Œæ•´å°è‚¡æ•¸æ“šæŠ“å–ç³»çµ±
"""
import os
import json
import time
import requests
import pandas as pd
import pytz
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
import logging
from urllib.parse import quote
import hashlib
import re

# å¯é¸çš„ç•°æ­¥æ”¯æ´æª¢æ¸¬
try:
    import aiohttp
    import asyncio
    ASYNC_SUPPORT = True
    print("âœ… ç•°æ­¥æ”¯æ´å·²å•Ÿç”¨")
except ImportError:
    ASYNC_SUPPORT = False
    print("âš ï¸ ç•°æ­¥æ”¯æ´æœªå•Ÿç”¨ï¼Œå°‡ä½¿ç”¨åŒæ­¥æ¨¡å¼")
    
    # æ¨¡æ“¬é¡åˆ¥ä»¥é¿å…å°å…¥éŒ¯èª¤
    class aiohttp:
        class ClientSession:
            def __init__(self, *args, **kwargs): pass
            def __enter__(self): return self
            def __exit__(self, *args): pass
        class ClientTimeout:
            def __init__(self, *args, **kwargs): pass
    
    class asyncio:
        @staticmethod
        def run(*args): return None

class IntegratedTWSEDataFetcher:
    """æ•´åˆç‰ˆå°è‚¡æ•¸æ“šç²å–å™¨"""
    
    def __init__(self, cache_dir: str = 'cache/stock_data'):
        """åˆå§‹åŒ–æ•¸æ“šç²å–å™¨"""
        self.cache_dir = cache_dir
        os.makedirs(cache_dir, exist_ok=True)
        
        # å°ç£æ™‚å€
        self.taipei_tz = pytz.timezone('Asia/Taipei')
        
        # è¨­ç½®æ—¥èªŒ
        self.logger = logging.getLogger(__name__)
        if not self.logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
            handler.setFormatter(formatter)
            self.logger.addHandler(handler)
            self.logger.setLevel(logging.INFO)
        
        # è«‹æ±‚æœƒè©±è¨­ç½®
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'application/json, text/javascript, */*; q=0.01',
            'Accept-Language': 'zh-TW,zh;q=0.9,en;q=0.8',
            'Referer': 'https://www.twse.com.tw/',
        })
        
        # æ•¸æ“šæºé…ç½®
        self.apis = {
            'twse_daily': 'https://www.twse.com.tw/exchangeReport/MI_INDEX',
            'twse_all': 'https://www.twse.com.tw/exchangeReport/STOCK_DAY_ALL',
            'tpex_daily': 'https://www.tpex.org.tw/web/stock/aftertrading/otc_quotes_no1430/stk_wn1430_result.php',
            'institutional': 'https://www.twse.com.tw/fund/T86',
        }
        
        # å¿«å–è¨­å®š
        self.cache_expire_hours = 1  # 1å°æ™‚éæœŸ
        
        # è«‹æ±‚é™åˆ¶
        self.request_delay = 0.5  # æ¯æ¬¡è«‹æ±‚é–“éš”0.5ç§’
        self.last_request_time = 0
        self.timeout = 30
        self.max_fallback_days = 5
    
    def get_current_taiwan_time(self) -> datetime:
        """ç²å–ç•¶å‰å°ç£æ™‚é–“"""
        return datetime.now(self.taipei_tz)
    
    def get_optimal_data_date(self) -> str:
        """ç²å–æœ€ä½³çš„æ•¸æ“šæ—¥æœŸ"""
        now = self.get_current_taiwan_time()
        
        # åˆ¤æ–·æœ€ä½³çš„æ•¸æ“šæ—¥æœŸ
        if now.weekday() == 0:  # é€±ä¸€
            target_date = now - timedelta(days=3)  # é€±äº”
        elif now.weekday() >= 5:  # é€±æœ«
            days_back = now.weekday() - 4  # å›åˆ°é€±äº”
            target_date = now - timedelta(days=days_back)
        elif now.hour < 9:  # æ—©ä¸Š9é»å‰
            target_date = now - timedelta(days=1)
        else:
            target_date = now
            
        return target_date.strftime('%Y%m%d')
    
    def _rate_limit(self):
        """è«‹æ±‚é »ç‡é™åˆ¶"""
        current_time = time.time()
        time_since_last = current_time - self.last_request_time
        
        if time_since_last < self.request_delay:
            sleep_time = self.request_delay - time_since_last
            time.sleep(sleep_time)
        
        self.last_request_time = time.time()
    
    def _get_cache_path(self, cache_key: str, date: str = None) -> str:
        """ç²å–å¿«å–æ–‡ä»¶è·¯å¾‘"""
        if date is None:
            date = datetime.now().strftime('%Y%m%d')
        return os.path.join(self.cache_dir, f"{cache_key}_{date}.json")
    
    def _is_cache_valid(self, cache_path: str) -> bool:
        """æª¢æŸ¥å¿«å–æ˜¯å¦æœ‰æ•ˆ"""
        if not os.path.exists(cache_path):
            return False
        
        file_time = os.path.getmtime(cache_path)
        current_time = time.time()
        
        return (current_time - file_time) < (self.cache_expire_hours * 3600)
    
    def _load_cache(self, cache_path: str) -> Optional[Any]:
        """è¼‰å…¥å¿«å–æ•¸æ“š"""
        try:
            with open(cache_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            self.logger.warning(f"è¼‰å…¥å¿«å–å¤±æ•—: {e}")
            return None
    
    def _save_cache(self, cache_path: str, data: Any):
        """ä¿å­˜å¿«å–æ•¸æ“š"""
        try:
            with open(cache_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            self.logger.debug(f"å¿«å–å·²ä¿å­˜: {cache_path}")
        except Exception as e:
            self.logger.warning(f"ä¿å­˜å¿«å–å¤±æ•—: {e}")
    
    def _safe_float(self, value: Any) -> float:
        """å®‰å…¨è½‰æ›ç‚ºæµ®é»æ•¸"""
        if not value or value in ["--", "N/A", "é™¤æ¬Šæ¯", "", "X"]:
            return 0.0
        try:
            if isinstance(value, (int, float)):
                return float(value)
            if isinstance(value, str):
                # è™•ç†é€—è™Ÿåˆ†éš”çš„æ•¸å­—å’Œç‰¹æ®Šç¬¦è™Ÿ
                cleaned = value.replace(',', '').replace(' ', '').replace('+', '').strip()
                if cleaned == '' or cleaned == '--' or cleaned == 'N/A':
                    return 0.0
                return float(cleaned)
            return float(value)
        except (ValueError, TypeError, AttributeError):
            return 0.0
    
    def _safe_int(self, value: Any) -> int:
        """å®‰å…¨è½‰æ›ç‚ºæ•´æ•¸"""
        try:
            if isinstance(value, int):
                return value
            if isinstance(value, str):
                cleaned = value.replace(',', '').replace(' ', '').strip()
                if cleaned == '' or cleaned == '--' or cleaned == 'N/A':
                    return 0
                return int(float(cleaned))
            return int(float(value))
        except (ValueError, TypeError, AttributeError):
            return 0
    
    def _parse_change(self, change_str: str) -> float:
        """è§£ææ¼²è·Œé‡‘é¡"""
        try:
            if not change_str or change_str.strip() == '':
                return 0.0
            
            # ç§»é™¤HTMLæ¨™ç±¤å’Œç‰¹æ®Šå­—ç¬¦
            cleaned = re.sub(r'<[^>]+>', '', str(change_str))
            cleaned = cleaned.replace(',', '').strip()
            
            # è™•ç†ç‰¹æ®Šç¬¦è™Ÿ
            if 'â–³' in cleaned or cleaned.startswith('+'):
                cleaned = cleaned.replace('â–³', '').replace('+', '')
                return abs(self._safe_float(cleaned))
            elif 'â–½' in cleaned or cleaned.startswith('-'):
                cleaned = cleaned.replace('â–½', '').replace('-', '')
                return -abs(self._safe_float(cleaned))
            else:
                return self._safe_float(cleaned)
                
        except Exception:
            return 0.0
    
    def fetch_twse_data(self, date: str = None) -> List[Dict[str, Any]]:
        """ç²å–è­‰äº¤æ‰€æ•¸æ“šï¼ˆå¤šç¨®æ–¹å¼å˜—è©¦ï¼‰"""
        if date is None:
            date = self.get_optimal_data_date()
        
        # æª¢æŸ¥å¿«å–
        cache_path = self._get_cache_path('twse_market', date)
        if self._is_cache_valid(cache_path):
            cached_data = self._load_cache(cache_path)
            if cached_data:
                self.logger.info(f"ä½¿ç”¨å¿«å–çš„TWSEæ•¸æ“š: {len(cached_data)} æ”¯è‚¡ç¥¨")
                return cached_data
        
        self.logger.info(f"å¾TWSEç²å– {date} çš„å¸‚å ´æ•¸æ“š...")
        
        # å˜—è©¦å¤šå€‹æ—¥æœŸå’ŒAPI
        for attempt in range(self.max_fallback_days):
            try:
                attempt_date = datetime.strptime(date, '%Y%m%d') - timedelta(days=attempt)
                if attempt_date.weekday() >= 5:  # è·³éé€±æœ«
                    continue
                    
                date_str = attempt_date.strftime('%Y%m%d')
                
                # æ–¹æ³•1: ä½¿ç”¨MI_INDEX API
                stocks = self._fetch_twse_mi_index(date_str)
                if stocks:
                    self.logger.info(f"æˆåŠŸç²å– {len(stocks)} æ”¯TWSEè‚¡ç¥¨ (MI_INDEX)")
                    self._save_cache(cache_path, stocks)
                    return stocks
                
                # æ–¹æ³•2: ä½¿ç”¨STOCK_DAY_ALL API
                stocks = self._fetch_twse_stock_day_all(date_str)
                if stocks:
                    self.logger.info(f"æˆåŠŸç²å– {len(stocks)} æ”¯TWSEè‚¡ç¥¨ (STOCK_DAY_ALL)")
                    self._save_cache(cache_path, stocks)
                    return stocks
                    
            except Exception as e:
                self.logger.warning(f"ç²å– {date_str} TWSEæ•¸æ“šå¤±æ•—: {e}")
                continue
        
        self.logger.error("æ‰€æœ‰å˜—è©¦éƒ½ç„¡æ³•ç²å–TWSEæ•¸æ“š")
        return []
    
    def _fetch_twse_mi_index(self, date: str) -> List[Dict[str, Any]]:
        """ä½¿ç”¨MI_INDEX APIç²å–TWSEæ•¸æ“š"""
        try:
            url = self.apis['twse_daily']
            params = {
                'response': 'json',
                'date': date,
                'type': 'ALL'
            }
            
            self._rate_limit()
            response = self.session.get(url, params=params, timeout=self.timeout)
            response.raise_for_status()
            
            data = response.json()
            
            if data.get('stat') != 'OK':
                raise Exception(f"APIç‹€æ…‹ç•°å¸¸: {data.get('stat')}")
            
            return self._parse_twse_mi_data(data, date)
            
        except Exception as e:
            self.logger.warning(f"MI_INDEX APIå¤±æ•—: {e}")
            return []
    
    def _fetch_twse_stock_day_all(self, date: str) -> List[Dict[str, Any]]:
        """ä½¿ç”¨STOCK_DAY_ALL APIç²å–TWSEæ•¸æ“š"""
        try:
            url = self.apis['twse_all']
            params = {
                'response': 'json',
                'date': date,
                'type': 'ALLBUT0999'
            }
            
            self._rate_limit()
            response = self.session.get(url, params=params, timeout=self.timeout)
            response.raise_for_status()
            
            data = response.json()
            
            if data.get('stat') != 'OK':
                raise Exception(f"APIç‹€æ…‹ç•°å¸¸: {data.get('stat')}")
            
            return self._parse_twse_stock_day_data(data, date)
            
        except Exception as e:
            self.logger.warning(f"STOCK_DAY_ALL APIå¤±æ•—: {e}")
            return []
    
    def _parse_twse_mi_data(self, data: Dict, date: str) -> List[Dict[str, Any]]:
        """è§£æMI_INDEXæ•¸æ“š"""
        stocks = []
        fields = data.get('fields', [])
        data_list = data.get('data9', [])  # ä¸€èˆ¬è‚¡ç¥¨æ•¸æ“š
        
        if not fields or not data_list:
            return []
        
        for row in data_list:
            try:
                if len(row) < len(fields):
                    continue
                
                stock_code = row[0].strip()
                stock_name = row[1].strip()
                
                # éæ¿¾éè‚¡ç¥¨ä»£ç¢¼
                if not stock_code.isdigit() or len(stock_code) != 4:
                    continue
                
                # è§£ææ•¸æ“š
                trade_volume = self._safe_int(row[2])
                trade_value = self._safe_int(row[3])
                open_price = self._safe_float(row[4])
                high_price = self._safe_float(row[5])
                low_price = self._safe_float(row[6])
                close_price = self._safe_float(row[7])
                
                # æ¼²è·Œä¿¡æ¯
                change_str = row[8].strip() if len(row) > 8 else ""
                change = self._parse_change(change_str)
                change_percent = (change / close_price * 100) if close_price > 0 else 0
                
                # åªä¿ç•™æœ‰äº¤æ˜“çš„è‚¡ç¥¨
                if close_price <= 0 or trade_volume <= 0:
                    continue
                
                stock = {
                    'code': stock_code,
                    'name': stock_name,
                    'market': 'TWSE',
                    'close': close_price,
                    'open': open_price,
                    'high': high_price,
                    'low': low_price,
                    'volume': trade_volume,
                    'trade_value': trade_value,
                    'change': change,
                    'change_percent': round(change_percent, 2),
                    'date': datetime.strptime(date, '%Y%m%d').strftime('%Y-%m-%d'),
                    'data_source': 'TWSE_MI_INDEX'
                }
                
                stocks.append(stock)
                
            except Exception as e:
                self.logger.debug(f"è§£æè‚¡ç¥¨æ•¸æ“šå¤±æ•—: {row[:2] if len(row) >= 2 else row}")
                continue
        
        return stocks
    
    def _parse_twse_stock_day_data(self, data: Dict, date: str) -> List[Dict[str, Any]]:
        """è§£æSTOCK_DAY_ALLæ•¸æ“š"""
        stocks = []
        fields = data.get("fields", [])
        raw_data = data.get("data", [])
        
        for row in raw_data:
            if len(row) >= len(fields):
                try:
                    stock_dict = dict(zip(fields, row))
                    
                    code = stock_dict.get("è­‰åˆ¸ä»£è™Ÿ", "").strip()
                    name = stock_dict.get("è­‰åˆ¸åç¨±", "").strip()
                    
                    if not code or not name:
                        continue
                    
                    close_price = self._safe_float(stock_dict.get("æ”¶ç›¤åƒ¹", "0"))
                    volume = self._safe_float(stock_dict.get("æˆäº¤è‚¡æ•¸", "0"))
                    change = self._safe_float(stock_dict.get("æ¼²è·Œåƒ¹å·®", "0"))
                    
                    if close_price <= 0:
                        continue
                    
                    change_percent = (change / close_price * 100) if close_price > 0 else 0
                    trade_value = volume * close_price
                    
                    stock = {
                        "code": code,
                        "name": name,
                        "market": "TWSE",
                        "close": close_price,
                        "open": self._safe_float(stock_dict.get("é–‹ç›¤åƒ¹", close_price)),
                        "high": self._safe_float(stock_dict.get("æœ€é«˜åƒ¹", close_price)),
                        "low": self._safe_float(stock_dict.get("æœ€ä½åƒ¹", close_price)),
                        "volume": int(volume),
                        "trade_value": trade_value,
                        "change": change,
                        "change_percent": round(change_percent, 2),
                        "date": datetime.strptime(date, '%Y%m%d').strftime('%Y-%m-%d'),
                        "data_source": "TWSE_STOCK_DAY_ALL"
                    }
                    
                    stocks.append(stock)
                    
                except Exception as e:
                    continue
        
        return stocks
    
    def fetch_tpex_data(self, date: str = None) -> List[Dict[str, Any]]:
        """ç²å–æ«ƒè²·ä¸­å¿ƒæ•¸æ“š"""
        if date is None:
            date = self.get_optimal_data_date()
        
        # æª¢æŸ¥å¿«å–
        cache_path = self._get_cache_path('tpex_market', date)
        if self._is_cache_valid(cache_path):
            cached_data = self._load_cache(cache_path)
            if cached_data:
                self.logger.info(f"ä½¿ç”¨å¿«å–çš„TPEXæ•¸æ“š: {len(cached_data)} æ”¯è‚¡ç¥¨")
                return cached_data
        
        self.logger.info(f"å¾TPEXç²å– {date} çš„ä¸Šæ«ƒæ•¸æ“š...")
        
        # å˜—è©¦å¤šå€‹æ—¥æœŸ
        for attempt in range(self.max_fallback_days):
            try:
                attempt_date = datetime.strptime(date, '%Y%m%d') - timedelta(days=attempt)
                if attempt_date.weekday() >= 5:  # è·³éé€±æœ«
                    continue
                
                # è½‰æ›ç‚ºæ°‘åœ‹å¹´æ ¼å¼
                minguo_year = attempt_date.year - 1911
                minguo_date = f"{minguo_year}/{attempt_date.month:02d}/{attempt_date.day:02d}"
                date_str = attempt_date.strftime('%Y%m%d')
                
                url = self.apis['tpex_daily']
                params = {
                    'l': 'zh-tw',
                    'd': minguo_date,
                    'se': 'EW',
                    'o': 'json'
                }
                
                self._rate_limit()
                response = self.session.get(url, params=params, timeout=self.timeout)
                response.raise_for_status()
                
                data = response.json()
                
                if data.get('stat') == 'OK' and data.get('iTotalRecords', 0) > 0:
                    stocks = self._parse_tpex_data(data, date_str)
                    if stocks:
                        self.logger.info(f"æˆåŠŸç²å– {len(stocks)} æ”¯TPEXè‚¡ç¥¨")
                        self._save_cache(cache_path, stocks)
                        return stocks
                        
            except Exception as e:
                self.logger.warning(f"ç²å–TPEXæ•¸æ“šå¤±æ•—: {e}")
                continue
        
        self.logger.error("æ‰€æœ‰å˜—è©¦éƒ½ç„¡æ³•ç²å–TPEXæ•¸æ“š")
        return []
    
    def _parse_tpex_data(self, data: Dict, date: str) -> List[Dict[str, Any]]:
        """è§£æTPEXæ•¸æ“š"""
        stocks = []
        data_list = data.get('aaData', [])
        
        for row in data_list:
            try:
                if len(row) < 10:
                    continue
                
                stock_code = row[0].strip()
                stock_name = row[1].strip()
                
                # éæ¿¾éè‚¡ç¥¨ä»£ç¢¼
                if not stock_code.isdigit():
                    continue
                
                close_price = self._safe_float(row[2])
                change = self._safe_float(row[3])
                open_price = self._safe_float(row[4])
                high_price = self._safe_float(row[5])
                low_price = self._safe_float(row[6])
                trade_volume = self._safe_int(row[7]) * 1000  # è½‰æ›ç‚ºè‚¡æ•¸
                trade_value = self._safe_int(row[8]) * 1000  # è½‰æ›ç‚ºå…ƒ
                
                change_percent = (change / close_price * 100) if close_price > 0 else 0
                
                # åªä¿ç•™æœ‰äº¤æ˜“çš„è‚¡ç¥¨
                if close_price <= 0 or trade_volume <= 0:
                    continue
                
                stock = {
                    'code': stock_code,
                    'name': stock_name,
                    'market': 'TPEX',
                    'close': close_price,
                    'open': open_price,
                    'high': high_price,
                    'low': low_price,
                    'volume': trade_volume,
                    'trade_value': trade_value,
                    'change': change,
                    'change_percent': round(change_percent, 2),
                    'date': datetime.strptime(date, '%Y%m%d').strftime('%Y-%m-%d'),
                    'data_source': 'TPEX_API'
                }
                
                stocks.append(stock)
                
            except Exception as e:
                self.logger.debug(f"è§£æTPEXè‚¡ç¥¨æ•¸æ“šå¤±æ•—: {row[:2] if len(row) >= 2 else row}")
                continue
        
        return stocks
    
    def fetch_institutional_data(self, date: str = None) -> Dict[str, Dict[str, int]]:
        """ç²å–ä¸‰å¤§æ³•äººè²·è³£è¶…æ•¸æ“š"""
        if date is None:
            date = self.get_optimal_data_date()
        
        # æª¢æŸ¥å¿«å–
        cache_path = self._get_cache_path('institutional', date)
        if self._is_cache_valid(cache_path):
            cached_data = self._load_cache(cache_path)
            if cached_data:
                self.logger.info(f"ä½¿ç”¨å¿«å–çš„æ³•äººæ•¸æ“š: {len(cached_data)} æ”¯è‚¡ç¥¨")
                return cached_data
        
        try:
            self.logger.info(f"ç²å– {date} çš„ä¸‰å¤§æ³•äººæ•¸æ“š...")
            
            url = self.apis['institutional']
            params = {
                'response': 'json',
                'date': date,
                'selectType': 'ALL'
            }
            
            self._rate_limit()
            response = self.session.get(url, params=params, timeout=self.timeout)
            response.raise_for_status()
            
            data = response.json()
            
            if data.get('stat') != 'OK':
                raise Exception(f"æ³•äººæ•¸æ“šAPIç‹€æ…‹ç•°å¸¸: {data.get('stat')}")
            
            # è§£ææ³•äººæ•¸æ“š
            institutional_data = {}
            data_list = data.get('data', [])
            
            for row in data_list:
                try:
                    if len(row) < 4:
                        continue
                    
                    stock_code = row[0].strip()
                    
                    # éæ¿¾éè‚¡ç¥¨ä»£ç¢¼
                    if not stock_code.isdigit() or len(stock_code) != 4:
                        continue
                    
                    # å¤–è³‡ã€æŠ•ä¿¡ã€è‡ªç‡Ÿå•†è²·è³£è¶…ï¼ˆå–®ä½ï¼šåƒè‚¡ï¼‰
                    foreign_net = self._safe_int(row[1]) * 1000  # è½‰æ›ç‚ºè‚¡æ•¸
                    trust_net = self._safe_int(row[2]) * 1000
                    dealer_net = self._safe_int(row[3]) * 1000
                    
                    institutional_data[stock_code] = {
                        'foreign_net_buy': foreign_net,
                        'trust_net_buy': trust_net,
                        'dealer_net_buy': dealer_net,
                        'total_net_buy': foreign_net + trust_net + dealer_net
                    }
                    
                except Exception as e:
                    continue
            
            self.logger.info(f"æˆåŠŸç²å– {len(institutional_data)} æ”¯è‚¡ç¥¨çš„æ³•äººæ•¸æ“š")
            
            # ä¿å­˜å¿«å–
            self._save_cache(cache_path, institutional_data)
            
            return institutional_data
            
        except Exception as e:
            self.logger.error(f"ç²å–æ³•äººæ•¸æ“šå¤±æ•—: {e}")
            return {}
    
    def get_financial_data(self, stock_codes: List[str]) -> Dict[str, Dict[str, Any]]:
        """ç²å–åŸºæœ¬é¢è²¡å‹™æ•¸æ“šï¼ˆæ¨¡æ“¬ç‰ˆæœ¬ï¼‰"""
        cache_path = self._get_cache_path('financial', datetime.now().strftime('%Y%m'))
        
        # åŸºæœ¬é¢æ•¸æ“šæ›´æ–°é »ç‡è¼ƒä½ï¼Œä½¿ç”¨æœˆåº¦å¿«å–
        if self._is_cache_valid(cache_path):
            cached_data = self._load_cache(cache_path)
            if cached_data:
                self.logger.info(f"ä½¿ç”¨å¿«å–çš„è²¡å‹™æ•¸æ“š: {len(cached_data)} æ”¯è‚¡ç¥¨")
                return {code: cached_data.get(code, {}) for code in stock_codes}
        
        try:
            self.logger.info(f"ç”Ÿæˆ {len(stock_codes)} æ”¯è‚¡ç¥¨çš„è²¡å‹™æ•¸æ“š...")
            
            financial_data = {}
            
            # é™åˆ¶è™•ç†æ•¸é‡é¿å…éé•·æ™‚é–“
            for i, stock_code in enumerate(stock_codes[:100]):
                try:
                    # ä½¿ç”¨è‚¡ç¥¨ä»£ç¢¼ç”Ÿæˆä¸€è‡´æ€§çš„æ¨¡æ“¬æ•¸æ“š
                    seed = int(hashlib.md5(stock_code.encode()).hexdigest()[:8], 16)
                    np.random.seed(seed)
                    
                    # æ ¹æ“šä¸åŒè‚¡ç¥¨é¡å‹è¨­å®šä¸åŒçš„è²¡å‹™ç‰¹å¾µ
                    if stock_code.startswith('23'):  # ç§‘æŠ€è‚¡
                        base_roe = np.random.normal(15, 5)
                        base_pe = np.random.normal(20, 8)
                        base_eps_growth = np.random.normal(12, 15)
                        base_dividend_yield = np.random.normal(2.5, 1.5)
                    elif stock_code.startswith('28'):  # é‡‘èè‚¡
                        base_roe = np.random.normal(10, 3)
                        base_pe = np.random.normal(12, 4)
                        base_eps_growth = np.random.normal(5, 8)
                        base_dividend_yield = np.random.normal(4.5, 1.5)
                    elif stock_code.startswith('26'):  # èˆªé‹è‚¡
                        base_roe = np.random.normal(20, 10)
                        base_pe = np.random.normal(8, 5)
                        base_eps_growth = np.random.normal(25, 20)
                        base_dividend_yield = np.random.normal(6, 2)
                    else:  # å…¶ä»–è‚¡ç¥¨
                        base_roe = np.random.normal(12, 6)
                        base_pe = np.random.normal(15, 6)
                        base_eps_growth = np.random.normal(8, 12)
                        base_dividend_yield = np.random.normal(3.5, 2)
                    
                    financial_data[stock_code] = {
                        'roe': max(0, round(base_roe, 1)),
                        'pe_ratio': max(3, round(base_pe, 1)),
                        'eps_growth': round(base_eps_growth, 1),
                        'dividend_yield': max(0, round(base_dividend_yield, 1)),
                        'revenue_growth': round(np.random.normal(base_eps_growth * 0.8, 8), 1),
                        'debt_ratio': round(np.random.uniform(0.2, 0.6), 2),
                        'current_ratio': round(np.random.uniform(1.0, 3.0), 2)
                    }
                    
                except Exception as e:
                    continue
            
            self.logger.info(f"æˆåŠŸç”Ÿæˆ {len(financial_data)} æ”¯è‚¡ç¥¨çš„è²¡å‹™æ•¸æ“š")
            
            # ä¿å­˜å¿«å–
            self._save_cache(cache_path, financial_data)
            
            return financial_data
            
        except Exception as e:
            self.logger.error(f"ç”Ÿæˆè²¡å‹™æ•¸æ“šå¤±æ•—: {e}")
            return {}
    
    def get_all_stocks_by_volume(self, date: str = None) -> List[Dict[str, Any]]:
        """ç²å–æ‰€æœ‰è‚¡ç¥¨ä¸¦æŒ‰æˆäº¤é‡‘é¡æ’åº"""
        self.logger.info("é–‹å§‹ç²å–æ‰€æœ‰è‚¡ç¥¨æ•¸æ“š")
        
        # ç²å–ä¸Šå¸‚è‚¡ç¥¨
        twse_stocks = self.fetch_twse_data(date)
        time.sleep(1)  # é¿å…è«‹æ±‚éæ–¼é »ç¹
        
        # ç²å–ä¸Šæ«ƒè‚¡ç¥¨
        tpex_stocks = self.fetch_tpex_data(date)
        
        # åˆä½µè‚¡ç¥¨æ•¸æ“š
        all_stocks = twse_stocks + tpex_stocks
        
        if not all_stocks:
            self.logger.error("ç„¡æ³•ç²å–ä»»ä½•è‚¡ç¥¨æ•¸æ“š")
            return []
        
        # ç²å–æ³•äººæ•¸æ“š
        institutional_data = self.fetch_institutional_data(date)
        
        # ç²å–è²¡å‹™æ•¸æ“šï¼ˆåƒ…å°å‰100æ”¯æ´»èºè‚¡ç¥¨ï¼‰
        top_stocks = sorted(all_stocks, key=lambda x: x.get('trade_value', 0), reverse=True)[:100]
        stock_codes = [s['code'] for s in top_stocks]
        financial_data = self.get_financial_data(stock_codes)
        
        # æ•´åˆæ•¸æ“š
        for stock in all_stocks:
            stock_code = stock['code']
            
            # æ·»åŠ æ³•äººæ•¸æ“š
            if stock_code in institutional_data:
                inst_data = institutional_data[stock_code]
                stock.update(inst_data)
            else:
                stock.update({
                    'foreign_net_buy': 0,
                    'trust_net_buy': 0,
                    'dealer_net_buy': 0,
                    'total_net_buy': 0
                })
            
            # æ·»åŠ è²¡å‹™æ•¸æ“š
            if stock_code in financial_data:
                stock.update(financial_data[stock_code])
        
        # éæ¿¾æœ‰æ•ˆæ•¸æ“š
        valid_stocks = [
            stock for stock in all_stocks 
            if stock.get('trade_value', 0) > 0 and stock.get('close', 0) > 0
        ]
        
        # æŒ‰æˆäº¤é‡‘é¡æ’åº
        sorted_stocks = sorted(valid_stocks, key=lambda x: x.get('trade_value', 0), reverse=True)
        
        self.logger.info(f"æˆåŠŸæ•´åˆä¸¦æ’åº {len(sorted_stocks)} æ”¯è‚¡ç¥¨")
        
        return sorted_stocks
    
    def get_stocks_by_time_slot(self, time_slot: str, date: str = None) -> List[Dict[str, Any]]:
        """æ ¹æ“šæ™‚æ®µç²å–ç›¸æ‡‰æ•¸é‡çš„è‚¡ç¥¨"""
        # å®šç¾©æ¯å€‹æ™‚æ®µçš„è‚¡ç¥¨æ•¸é‡
        slot_limits = {
            'morning_scan': 200,
            'mid_morning_scan': 300,
            'mid_day_scan': 300,
            'afternoon_scan': 1000,
            'weekly_summary': 500
        }
        
        limit = slot_limits.get(time_slot, 200)
        
        self.logger.info(f"ç²å– {time_slot} æ™‚æ®µçš„å‰ {limit} æ”¯è‚¡ç¥¨")
        
        # ç²å–æ‰€æœ‰è‚¡ç¥¨
        all_stocks = self.get_all_stocks_by_volume(date)
        
        # æ ¹æ“šæ™‚æ®µç¯©é¸å’Œæ’åº
        filtered_stocks = self._filter_stocks_by_time_slot(all_stocks, time_slot)
        
        # æ·»åŠ æ™‚æ®µè³‡è¨Š
        for stock in filtered_stocks:
            stock['time_slot'] = time_slot
        
        self.logger.info(f"ç‚º {time_slot} æ™‚æ®µé¸æ“‡äº† {len(filtered_stocks)} æ”¯è‚¡ç¥¨")
        
        return filtered_stocks
    
    def _filter_stocks_by_time_slot(self, stocks: List[Dict[str, Any]], time_slot: str) -> List[Dict[str, Any]]:
        """æ ¹æ“šæ™‚æ®µç¯©é¸è‚¡ç¥¨"""
        
        # åŸºæœ¬ç¯©é¸æ¢ä»¶
        valid_stocks = [
            stock for stock in stocks
            if stock.get('close', 0) > 0 
            and stock.get('trade_value', 0) > 100000  # è‡³å°‘10è¬æˆäº¤é‡‘é¡
            and stock.get('volume', 0) > 1000  # è‡³å°‘1000è‚¡æˆäº¤é‡
        ]
        
        # æ ¹æ“šæ™‚æ®µè¨­å®šä¸åŒçš„ç¯©é¸å’Œæ’åºç­–ç•¥
        if time_slot == 'morning_scan':
            # æ—©ç›¤é—œæ³¨æ´»èºè‚¡ç¥¨
            valid_stocks.sort(key=lambda x: x.get('trade_value', 0), reverse=True)
            return valid_stocks[:200]
            
        elif time_slot == 'afternoon_scan':
            # ç›¤å¾Œç¶œåˆåˆ†æï¼ŒåŒ…å«æ›´å¤šè‚¡ç¥¨
            valid_stocks.sort(key=lambda x: (
                x.get('trade_value', 0) * 0.7 + 
                abs(x.get('change_percent', 0)) * x.get('close', 0) * x.get('volume', 0) * 0.3
            ), reverse=True)
            return valid_stocks[:1000]
            
        elif time_slot == 'weekly_summary':
            # é€±æœ«ç¸½çµï¼Œå…¨é¢åˆ†æ
            valid_stocks.sort(key=lambda x: x.get('trade_value', 0), reverse=True)
            return valid_stocks[:500]
            
        else:
            # å…¶ä»–æ™‚æ®µ
            valid_stocks.sort(key=lambda x: x.get('trade_value', 0), reverse=True)
            return valid_stocks[:300]
    
    def test_connection(self) -> Dict[str, bool]:
        """æ¸¬è©¦æ‰€æœ‰æ•¸æ“šæºé€£æ¥"""
        results = {}
        test_date = self.get_optimal_data_date()
        
        # æ¸¬è©¦TWSEé€£æ¥
        try:
            twse_data = self.fetch_twse_data(test_date)
            results['twse'] = len(twse_data) > 0
            print(f"âœ… TWSEé€£æ¥æ¸¬è©¦: ç²å– {len(twse_data)} æ”¯è‚¡ç¥¨")
        except Exception as e:
            results['twse'] = False
            print(f"âŒ TWSEé€£æ¥æ¸¬è©¦å¤±æ•—: {e}")
        
        # æ¸¬è©¦TPEXé€£æ¥
        try:
            tpex_data = self.fetch_tpex_data(test_date)
            results['tpex'] = len(tpex_data) > 0
            print(f"âœ… TPEXé€£æ¥æ¸¬è©¦: ç²å– {len(tpex_data)} æ”¯è‚¡ç¥¨")
        except Exception as e:
            results['tpex'] = False
            print(f"âŒ TPEXé€£æ¥æ¸¬è©¦å¤±æ•—: {e}")
        
        # æ¸¬è©¦æ³•äººæ•¸æ“š
        try:
            inst_data = self.fetch_institutional_data(test_date)
            results['institutional'] = len(inst_data) > 0
            print(f"âœ… æ³•äººæ•¸æ“šæ¸¬è©¦: ç²å– {len(inst_data)} æ”¯è‚¡ç¥¨")
        except Exception as e:
            results['institutional'] = False
            print(f"âŒ æ³•äººæ•¸æ“šæ¸¬è©¦å¤±æ•—: {e}")
        
        return results

# æ¸¬è©¦å’Œä½¿ç”¨ç¤ºä¾‹
def test_integrated_fetcher():
    """æ¸¬è©¦æ•´åˆç‰ˆæ•¸æ“šæŠ“å–å™¨"""
    print("ğŸ§ª æ¸¬è©¦ IntegratedTWSEDataFetcher...")
    
    try:
        # è¨­ç½®æ—¥èªŒç´šåˆ¥
        logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
        
        # å‰µå»ºæ•¸æ“šç²å–å™¨
        fetcher = IntegratedTWSEDataFetcher()
        print("âœ… IntegratedTWSEDataFetcher åˆå§‹åŒ–æˆåŠŸ")
        
        # æ¸¬è©¦æ•¸æ“šæºé€£æ¥
        print("\nğŸ” æ¸¬è©¦æ•¸æ“šæºé€£æ¥...")
        test_results = fetcher.test_connection()
        
        # æ¸¬è©¦ç²å–è‚¡ç¥¨æ•¸æ“š
        print("\nğŸ“Š æ¸¬è©¦ç²å–è‚¡ç¥¨æ•¸æ“š...")
        stocks = fetcher.get_stocks_by_time_slot('morning_scan')
        
        if stocks:
            print(f"âœ… æˆåŠŸç²å– {len(stocks)} æ”¯è‚¡ç¥¨æ•¸æ“š")
            print(f"\nğŸ“ˆ å‰5æ”¯æœ€æ´»èºè‚¡ç¥¨:")
            for i, stock in enumerate(stocks[:5]):
                print(f"  {i+1}. {stock['code']} {stock['name']} ({stock['market']})")
                print(f"     åƒ¹æ ¼: {stock['close']:.2f} ({stock['change_percent']:+.2f}%)")
                print(f"     æˆäº¤å€¼: {stock['trade_value']:,.0f} å…ƒ")
                if 'foreign_net_buy' in stock:
                    print(f"     å¤–è³‡: {stock['foreign_net_buy']:,} è‚¡")
                print()
        else:
            print("âš ï¸ æ²’æœ‰ç²å–åˆ°è‚¡ç¥¨æ•¸æ“š")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = test_integrated_fetcher()
    if success:
        print("ğŸ‰ æ•´åˆç‰ˆå°è‚¡æ•¸æ“šç²å–å™¨æ¸¬è©¦å®Œæˆï¼")
    else:
        print("ğŸ’¥ æ¸¬è©¦å¤±æ•—ï¼Œè«‹æª¢æŸ¥éŒ¯èª¤ä¿¡æ¯")
