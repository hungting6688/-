"""
news_sentiment.py - æ–°èæƒ…ç·’åˆ†æç³»çµ±
çˆ¬å–è²¡ç¶“æ–°èä¸¦åˆ†æå¸‚å ´æƒ…ç·’

åŠŸèƒ½ï¼š
1. å¤šä¾†æºæ–°èçˆ¬å–ï¼ˆYahoo è²¡ç¶“ã€é‰…äº¨ç¶²ã€ç¶“æ¿Ÿæ—¥å ±ç­‰ï¼‰
2. ä¸­æ–‡æƒ…ç·’åˆ†æ
3. è‚¡ç¥¨ç›¸é—œæ–°èéæ¿¾
4. æƒ…ç·’åˆ†æ•¸è¨ˆç®—
"""

import requests
import re
import json
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
from bs4 import BeautifulSoup
import time

logger = logging.getLogger(__name__)

# å˜—è©¦å°å…¥ jieba é€²è¡Œä¸­æ–‡åˆ†è©
try:
    import jieba
    JIEBA_AVAILABLE = True
except ImportError:
    JIEBA_AVAILABLE = False
    logger.info("jieba æœªå®‰è£ï¼Œä½¿ç”¨ç°¡åŒ–ç‰ˆæœ¬")


class ChineseSentimentAnalyzer:
    """
    ä¸­æ–‡æƒ…ç·’åˆ†æå™¨
    ä½¿ç”¨è©å…¸æ³•é€²è¡Œæƒ…ç·’åˆ†æ
    """

    def __init__(self):
        # æ­£é¢è©å½™ï¼ˆè‚¡å¸‚ç›¸é—œï¼‰
        self.positive_words = {
            # å¼·çƒˆæ­£é¢
            'å¤§æ¼²', 'æš´æ¼²', 'é£†å‡', 'é£†æ¼²', 'å¼·æ¼²', 'æ€¥æ¼²', 'å‰µæ–°é«˜',
            'çªç ´', 'å™´å‡º', 'äº•å™´', 'çˆ†é‡', 'å¤§è²·è¶…', 'ç‹‚è²·',
            # æ­£é¢
            'ä¸Šæ¼²', 'æ¼²', 'æ¼²åœ', 'ç´…ç›¤', 'æ”¶ç´…', 'èµ°é«˜', 'æ”€å‡',
            'å›å‡', 'åå½ˆ', 'è½‰å¼·', 'ä¸Šæš', 'èµ°æš', 'æ‹‰å‡',
            'è²·é€²', 'è²·è¶…', 'è²·ç›¤', 'åŠ ç¢¼', 'å¸ƒå±€', 'å¡ä½',
            'çœ‹å¥½', 'çœ‹å¤š', 'çœ‹æ¼²', 'æ¨‚è§€', 'åˆ©å¤š', 'æ­£é¢',
            'æˆé•·', 'ç²åˆ©', 'ç›ˆé¤˜', 'ç‡Ÿæ”¶å¢', 'æ¥­ç¸¾ä½³',
            'å‰µé«˜', 'æ–°é«˜', 'æ­·å²é«˜', 'äº®çœ¼', 'å„ªæ–¼é æœŸ',
            'æ¨è–¦', 'é¦–é¸', 'æ½›åŠ›', 'é¡Œæ', 'ç†±é–€',
            'å¤–è³‡è²·', 'æ³•äººè²·', 'æŠ•ä¿¡è²·', 'ä¸»åŠ›è²·'
        }

        # è² é¢è©å½™
        self.negative_words = {
            # å¼·çƒˆè² é¢
            'å¤§è·Œ', 'æš´è·Œ', 'å´©ç›¤', 'å´©è·Œ', 'æ€¥è·Œ', 'é‡æŒ«', 'æ…˜è·Œ',
            'è·³æ°´', 'æ®ºç›¤', 'å€’è²¨', 'å¤§è³£è¶…', 'ç‹‚è³£',
            # è² é¢
            'ä¸‹è·Œ', 'è·Œ', 'è·Œåœ', 'ç¶ ç›¤', 'æ”¶é»‘', 'èµ°ä½', 'ä¸‹æŒ«',
            'å›è½', 'å›æª”', 'è½‰å¼±', 'ä¸‹æ¢', 'ç ´åº•', 'æ¢åº•',
            'è³£å‡º', 'è³£è¶…', 'è³£å£“', 'æ¸›ç¢¼', 'å‡ºè„«', 'ç²åˆ©äº†çµ',
            'çœ‹å£', 'çœ‹ç©º', 'çœ‹è·Œ', 'æ‚²è§€', 'åˆ©ç©º', 'è² é¢',
            'è¡°é€€', 'è™§æ', 'ä¸‹æ»‘', 'ç‡Ÿæ”¶æ¸›', 'æ¥­ç¸¾å·®',
            'å‰µä½', 'æ–°ä½', 'è·Œç ´', 'ä½æ–¼é æœŸ',
            'å¤–è³‡è³£', 'æ³•äººè³£', 'æŠ•ä¿¡è³£', 'ä¸»åŠ›è³£',
            'è­¦ç¤º', 'é¢¨éšª', 'å±æ©Ÿ', 'æ³¡æ²«', 'éç†±'
        }

        # ç¨‹åº¦å‰¯è©
        self.intensifiers = {
            'å¤§': 1.5, 'éå¸¸': 1.5, 'æ¥µ': 2.0, 'è¶…': 1.5,
            'ç‰¹åˆ¥': 1.3, 'ç›¸ç•¶': 1.2, 'å¾ˆ': 1.2, 'æ›´': 1.2,
            'æŒçºŒ': 1.1, 'é€£çºŒ': 1.2, 'å†': 1.1
        }

        # å¦å®šè©
        self.negations = {'ä¸', 'æ²’', 'æœª', 'é', 'ç„¡', 'é›£'}

    def analyze(self, text: str) -> Dict[str, Any]:
        """
        åˆ†ææ–‡æœ¬æƒ…ç·’

        Returns:
            {
                'score': float,  # -1 åˆ° 1
                'sentiment': str,  # positive, negative, neutral
                'confidence': float,
                'positive_count': int,
                'negative_count': int,
                'keywords': List[str]
            }
        """
        if not text:
            return {'score': 0, 'sentiment': 'neutral', 'confidence': 0}

        # åˆ†è©
        if JIEBA_AVAILABLE:
            words = list(jieba.cut(text))
        else:
            words = list(text)  # ç°¡å–®æŒ‰å­—åˆ†å‰²

        positive_count = 0
        negative_count = 0
        positive_score = 0
        negative_score = 0
        keywords = []

        # è¨ˆç®—æƒ…ç·’åˆ†æ•¸
        i = 0
        while i < len(words):
            word = words[i]

            # æª¢æŸ¥ç¨‹åº¦å‰¯è©
            intensity = 1.0
            if i > 0 and words[i-1] in self.intensifiers:
                intensity = self.intensifiers[words[i-1]]

            # æª¢æŸ¥å¦å®š
            negated = i > 0 and words[i-1] in self.negations

            if word in self.positive_words:
                if negated:
                    negative_count += 1
                    negative_score += intensity
                else:
                    positive_count += 1
                    positive_score += intensity
                    keywords.append(word)

            elif word in self.negative_words:
                if negated:
                    positive_count += 1
                    positive_score += intensity
                else:
                    negative_count += 1
                    negative_score += intensity
                    keywords.append(word)

            # æª¢æŸ¥è©çµ„ï¼ˆå…©å€‹å­—ä»¥ä¸Šï¼‰
            if i < len(words) - 1:
                bigram = word + words[i+1]
                if bigram in self.positive_words:
                    positive_count += 1
                    positive_score += intensity * 1.2
                    keywords.append(bigram)
                elif bigram in self.negative_words:
                    negative_count += 1
                    negative_score += intensity * 1.2
                    keywords.append(bigram)

            i += 1

        # è¨ˆç®—æœ€çµ‚åˆ†æ•¸
        total = positive_score + negative_score
        if total == 0:
            score = 0
            confidence = 0
        else:
            score = (positive_score - negative_score) / total
            confidence = min(total / 10, 1.0)  # è¶Šå¤šé—œéµè©ä¿¡å¿ƒè¶Šé«˜

        # åˆ¤æ–·æƒ…ç·’
        if score > 0.2:
            sentiment = 'positive'
        elif score < -0.2:
            sentiment = 'negative'
        else:
            sentiment = 'neutral'

        return {
            'score': round(score, 4),
            'sentiment': sentiment,
            'confidence': round(confidence, 4),
            'positive_count': positive_count,
            'negative_count': negative_count,
            'keywords': list(set(keywords))[:10]
        }


class NewsCollector:
    """
    æ–°èæ”¶é›†å™¨
    å¾å¤šå€‹ä¾†æºæ”¶é›†è²¡ç¶“æ–°è
    """

    def __init__(self):
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        self.request_delay = 1.0

    def collect_yahoo_finance_news(self, stock_code: str = None,
                                   limit: int = 10) -> List[Dict]:
        """
        å¾ Yahoo è²¡ç¶“æ”¶é›†æ–°è
        """
        news_list = []

        try:
            if stock_code:
                # å€‹è‚¡æ–°è
                url = f"https://tw.stock.yahoo.com/quote/{stock_code}.TW/news"
            else:
                # ä¸€èˆ¬è²¡ç¶“æ–°è
                url = "https://tw.stock.yahoo.com/news"

            response = requests.get(url, headers=self.headers, timeout=10)
            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')

                # æ‰¾æ–°èæ¨™é¡Œ
                articles = soup.find_all('h3', class_=re.compile('Mb'))
                for article in articles[:limit]:
                    title = article.get_text().strip()
                    link = article.find('a')
                    href = link.get('href', '') if link else ''

                    if title:
                        news_list.append({
                            'title': title,
                            'link': href,
                            'source': 'Yahooè²¡ç¶“',
                            'timestamp': datetime.now().isoformat()
                        })

        except Exception as e:
            logger.warning(f"Yahoo è²¡ç¶“æ–°èç²å–å¤±æ•—: {e}")

        return news_list

    def collect_cnyes_news(self, limit: int = 10) -> List[Dict]:
        """
        å¾é‰…äº¨ç¶²æ”¶é›†æ–°è
        """
        news_list = []

        try:
            url = "https://news.cnyes.com/api/v3/news/category/tw_stock"
            params = {'limit': limit}

            response = requests.get(url, params=params, headers=self.headers, timeout=10)
            if response.status_code == 200:
                data = response.json()
                items = data.get('items', {}).get('data', [])

                for item in items:
                    news_list.append({
                        'title': item.get('title', ''),
                        'summary': item.get('summary', ''),
                        'link': f"https://news.cnyes.com/news/id/{item.get('newsId', '')}",
                        'source': 'é‰…äº¨ç¶²',
                        'timestamp': item.get('publishAt', datetime.now().isoformat())
                    })

        except Exception as e:
            logger.warning(f"é‰…äº¨ç¶²æ–°èç²å–å¤±æ•—: {e}")

        return news_list

    def collect_udn_news(self, limit: int = 10) -> List[Dict]:
        """
        å¾ç¶“æ¿Ÿæ—¥å ±æ”¶é›†æ–°è
        """
        news_list = []

        try:
            url = "https://money.udn.com/rank/newest/1001/0/0"

            response = requests.get(url, headers=self.headers, timeout=10)
            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')

                articles = soup.find_all('div', class_='story-content')
                for article in articles[:limit]:
                    title_elem = article.find('a', class_='story-title')
                    if title_elem:
                        title = title_elem.get_text().strip()
                        href = title_elem.get('href', '')

                        news_list.append({
                            'title': title,
                            'link': f"https://money.udn.com{href}" if href.startswith('/') else href,
                            'source': 'ç¶“æ¿Ÿæ—¥å ±',
                            'timestamp': datetime.now().isoformat()
                        })

        except Exception as e:
            logger.warning(f"ç¶“æ¿Ÿæ—¥å ±æ–°èç²å–å¤±æ•—: {e}")

        return news_list

    def collect_all_news(self, stock_code: str = None, limit: int = 30) -> List[Dict]:
        """
        å¾æ‰€æœ‰ä¾†æºæ”¶é›†æ–°è
        """
        all_news = []

        # Yahoo è²¡ç¶“
        yahoo_news = self.collect_yahoo_finance_news(stock_code, limit=limit//3)
        all_news.extend(yahoo_news)
        time.sleep(self.request_delay)

        # é‰…äº¨ç¶²
        cnyes_news = self.collect_cnyes_news(limit=limit//3)
        all_news.extend(cnyes_news)
        time.sleep(self.request_delay)

        # ç¶“æ¿Ÿæ—¥å ±
        udn_news = self.collect_udn_news(limit=limit//3)
        all_news.extend(udn_news)

        return all_news


class NewsSentimentSystem:
    """
    æ–°èæƒ…ç·’åˆ†æç³»çµ±
    æ•´åˆæ–°èæ”¶é›†å’Œæƒ…ç·’åˆ†æ
    """

    def __init__(self):
        self.collector = NewsCollector()
        self.analyzer = ChineseSentimentAnalyzer()

    def analyze_market_sentiment(self, limit: int = 30) -> Dict[str, Any]:
        """
        åˆ†ææ•´é«”å¸‚å ´æƒ…ç·’

        Returns:
            {
                'overall_score': float,  # -1 åˆ° 1
                'sentiment': str,
                'confidence': float,
                'positive_ratio': float,
                'negative_ratio': float,
                'top_positive_news': List,
                'top_negative_news': List,
                'keywords': List
            }
        """
        # æ”¶é›†æ–°è
        news_list = self.collector.collect_all_news(limit=limit)

        if not news_list:
            return {
                'overall_score': 0,
                'sentiment': 'neutral',
                'confidence': 0,
                'news_count': 0
            }

        # åˆ†ææ¯æ¢æ–°è
        analyzed_news = []
        all_keywords = []

        for news in news_list:
            text = news.get('title', '') + ' ' + news.get('summary', '')
            result = self.analyzer.analyze(text)

            analyzed_news.append({
                **news,
                'sentiment_score': result['score'],
                'sentiment': result['sentiment'],
                'keywords': result['keywords']
            })

            all_keywords.extend(result['keywords'])

        # è¨ˆç®—æ•´é«”æƒ…ç·’
        scores = [n['sentiment_score'] for n in analyzed_news]
        overall_score = sum(scores) / len(scores) if scores else 0

        positive_count = sum(1 for n in analyzed_news if n['sentiment'] == 'positive')
        negative_count = sum(1 for n in analyzed_news if n['sentiment'] == 'negative')

        # è¨ˆç®—ä¿¡å¿ƒåº¦
        confidence = min(len(analyzed_news) / 20, 1.0) * min(abs(overall_score) * 2, 1.0)

        # åˆ¤æ–·æƒ…ç·’
        if overall_score > 0.15:
            sentiment = 'positive'
        elif overall_score < -0.15:
            sentiment = 'negative'
        else:
            sentiment = 'neutral'

        # æ‰¾å‡ºæœ€æ­£é¢å’Œæœ€è² é¢çš„æ–°è
        sorted_by_score = sorted(analyzed_news, key=lambda x: x['sentiment_score'], reverse=True)
        top_positive = [n for n in sorted_by_score[:5] if n['sentiment_score'] > 0]
        top_negative = [n for n in sorted_by_score[-5:] if n['sentiment_score'] < 0]

        # çµ±è¨ˆé—œéµè©
        keyword_counts = {}
        for kw in all_keywords:
            keyword_counts[kw] = keyword_counts.get(kw, 0) + 1
        top_keywords = sorted(keyword_counts.items(), key=lambda x: x[1], reverse=True)[:10]

        return {
            'overall_score': round(overall_score, 4),
            'sentiment': sentiment,
            'confidence': round(confidence, 4),
            'news_count': len(analyzed_news),
            'positive_ratio': positive_count / len(analyzed_news) if analyzed_news else 0,
            'negative_ratio': negative_count / len(analyzed_news) if analyzed_news else 0,
            'top_positive_news': top_positive[:3],
            'top_negative_news': top_negative[:3],
            'keywords': [kw[0] for kw in top_keywords],
            'analyzed_news': analyzed_news[:10]  # è¿”å›å‰10æ¢åˆ†æçµæœ
        }

    def analyze_stock_sentiment(self, stock_code: str,
                                stock_name: str = None) -> Dict[str, Any]:
        """
        åˆ†æç‰¹å®šè‚¡ç¥¨çš„æ–°èæƒ…ç·’
        """
        # æ”¶é›†è©²è‚¡ç¥¨ç›¸é—œæ–°è
        news_list = self.collector.collect_yahoo_finance_news(stock_code, limit=20)

        # ä¹Ÿæœå°‹è‚¡ç¥¨åç¨±ç›¸é—œæ–°è
        if stock_name:
            all_news = self.collector.collect_all_news(limit=30)
            related_news = [n for n in all_news
                          if stock_code in n.get('title', '') or
                          stock_name in n.get('title', '')]
            news_list.extend(related_news)

        if not news_list:
            return {
                'stock_code': stock_code,
                'overall_score': 0,
                'sentiment': 'neutral',
                'confidence': 0,
                'news_count': 0
            }

        # åˆ†æ
        analyzed = []
        for news in news_list:
            text = news.get('title', '') + ' ' + news.get('summary', '')
            result = self.analyzer.analyze(text)
            analyzed.append({
                **news,
                'sentiment_score': result['score'],
                'sentiment': result['sentiment']
            })

        scores = [n['sentiment_score'] for n in analyzed]
        overall_score = sum(scores) / len(scores) if scores else 0

        return {
            'stock_code': stock_code,
            'stock_name': stock_name,
            'overall_score': round(overall_score, 4),
            'sentiment': 'positive' if overall_score > 0.15 else ('negative' if overall_score < -0.15 else 'neutral'),
            'confidence': min(len(analyzed) / 10, 1.0),
            'news_count': len(analyzed),
            'latest_news': analyzed[:5]
        }

    def get_sentiment_signal(self) -> Dict[str, Any]:
        """
        ç²å–æƒ…ç·’ä¿¡è™Ÿï¼ˆç”¨æ–¼äº¤æ˜“ç­–ç•¥ï¼‰

        Returns:
            {
                'signal': int,  # -1, 0, 1
                'strength': float,  # 0 åˆ° 1
                'description': str
            }
        """
        result = self.analyze_market_sentiment(limit=20)

        score = result['overall_score']
        confidence = result['confidence']

        # è¨ˆç®—ä¿¡è™Ÿ
        if score > 0.3 and confidence > 0.5:
            signal = 1
            strength = min(score * confidence * 2, 1.0)
            description = 'å¸‚å ´æƒ…ç·’æ¨‚è§€ï¼Œæ–°èé¢åå¤š'
        elif score < -0.3 and confidence > 0.5:
            signal = -1
            strength = min(abs(score) * confidence * 2, 1.0)
            description = 'å¸‚å ´æƒ…ç·’æ‚²è§€ï¼Œæ–°èé¢åç©º'
        elif score > 0.15:
            signal = 1
            strength = score * confidence
            description = 'å¸‚å ´æƒ…ç·’ç•¥åæ¨‚è§€'
        elif score < -0.15:
            signal = -1
            strength = abs(score) * confidence
            description = 'å¸‚å ´æƒ…ç·’ç•¥åæ‚²è§€'
        else:
            signal = 0
            strength = 0
            description = 'å¸‚å ´æƒ…ç·’ä¸­æ€§'

        return {
            'signal': signal,
            'strength': round(strength, 4),
            'description': description,
            'raw_score': score,
            'keywords': result.get('keywords', [])[:5],
            'news_count': result.get('news_count', 0)
        }


# ==================== æ•´åˆåˆ°é æ¸¬ç³»çµ± ====================

class SentimentEnhancedPredictor:
    """
    æƒ…ç·’å¢å¼·é æ¸¬å™¨
    çµåˆæ–°èæƒ…ç·’èˆ‡æŠ€è¡“åˆ†æ
    """

    def __init__(self):
        self.sentiment_system = NewsSentimentSystem()
        self.sentiment_weight = 0.2  # æƒ…ç·’åœ¨æœ€çµ‚é æ¸¬ä¸­çš„æ¬Šé‡

    def get_enhanced_prediction(self, technical_score: float,
                                stock_code: str = None,
                                stock_name: str = None) -> Dict[str, Any]:
        """
        ç²å–æƒ…ç·’å¢å¼·å¾Œçš„é æ¸¬

        Args:
            technical_score: æŠ€è¡“åˆ†æåˆ†æ•¸ (-1 åˆ° 1)
            stock_code: è‚¡ç¥¨ä»£ç¢¼ï¼ˆå¯é¸ï¼‰
            stock_name: è‚¡ç¥¨åç¨±ï¼ˆå¯é¸ï¼‰

        Returns:
            å¢å¼·å¾Œçš„é æ¸¬çµæœ
        """
        # ç²å–å¸‚å ´æƒ…ç·’
        market_sentiment = self.sentiment_system.get_sentiment_signal()

        # å¦‚æœæœ‰è‚¡ç¥¨ä»£ç¢¼ï¼Œç²å–å€‹è‚¡æƒ…ç·’
        stock_sentiment = None
        if stock_code:
            try:
                stock_sentiment = self.sentiment_system.analyze_stock_sentiment(
                    stock_code, stock_name
                )
            except Exception as e:
                logger.warning(f"å€‹è‚¡æƒ…ç·’åˆ†æå¤±æ•—: {e}")

        # è¨ˆç®—æƒ…ç·’åˆ†æ•¸
        sentiment_score = market_sentiment['raw_score']
        if stock_sentiment and stock_sentiment['confidence'] > 0.3:
            # çµåˆå€‹è‚¡å’Œå¸‚å ´æƒ…ç·’
            sentiment_score = (
                market_sentiment['raw_score'] * 0.4 +
                stock_sentiment['overall_score'] * 0.6
            )

        # çµåˆæŠ€è¡“åˆ†æå’Œæƒ…ç·’åˆ†æ
        combined_score = (
            technical_score * (1 - self.sentiment_weight) +
            sentiment_score * self.sentiment_weight
        )

        # åˆ¤æ–·æœ€çµ‚ä¿¡è™Ÿ
        if combined_score > 0.3:
            signal = 'bullish'
            action = 'è²·å…¥'
        elif combined_score > 0.1:
            signal = 'slightly_bullish'
            action = 'åå¤šè§€æœ›'
        elif combined_score < -0.3:
            signal = 'bearish'
            action = 'è³£å‡º'
        elif combined_score < -0.1:
            signal = 'slightly_bearish'
            action = 'åç©ºè§€æœ›'
        else:
            signal = 'neutral'
            action = 'è§€æœ›'

        return {
            'combined_score': round(combined_score, 4),
            'technical_score': round(technical_score, 4),
            'sentiment_score': round(sentiment_score, 4),
            'signal': signal,
            'action': action,
            'market_sentiment': market_sentiment,
            'stock_sentiment': stock_sentiment,
            'sentiment_keywords': market_sentiment.get('keywords', [])
        }


# ==================== æ¸¬è©¦ ====================

if __name__ == '__main__':
    logging.basicConfig(level=logging.INFO)

    print("=" * 60)
    print("ğŸ“° æ–°èæƒ…ç·’åˆ†æç³»çµ±æ¸¬è©¦")
    print("=" * 60)

    # æ¸¬è©¦æƒ…ç·’åˆ†æå™¨
    print("\n1. ä¸­æ–‡æƒ…ç·’åˆ†ææ¸¬è©¦")
    analyzer = ChineseSentimentAnalyzer()

    test_texts = [
        "å°ç©é›»å¤§æ¼²å‰µæ–°é«˜ï¼Œå¤–è³‡æŒçºŒè²·è¶…",
        "è‚¡å¸‚å´©ç›¤æš´è·Œï¼ŒæŠ•è³‡äººææ…Œæ‹‹å”®",
        "ä»Šæ—¥å¤§ç›¤å°æ¼²ï¼Œæˆäº¤é‡æŒå¹³",
        "æ³•äººçœ‹å¥½åŠå°é«”å‰æ™¯ï¼Œå»ºè­°åŠ ç¢¼å¸ƒå±€",
        "ç‡Ÿæ”¶è¡°é€€ï¼Œå…¬å¸ç™¼å¸ƒç²åˆ©è­¦è¨Š"
    ]

    for text in test_texts:
        result = analyzer.analyze(text)
        print(f"æ–‡æœ¬: {text}")
        print(f"  â†’ æƒ…ç·’: {result['sentiment']}, åˆ†æ•¸: {result['score']:.2f}")
        print(f"  â†’ é—œéµè©: {result['keywords']}")
        print()

    # æ¸¬è©¦æ–°èæ”¶é›†ï¼ˆéœ€è¦ç¶²è·¯ï¼‰
    print("2. æ–°èæ”¶é›†æ¸¬è©¦")
    collector = NewsCollector()
    try:
        news = collector.collect_cnyes_news(limit=3)
        print(f"é‰…äº¨ç¶²æ–°è: ç²å– {len(news)} æ¢")
        for n in news[:2]:
            print(f"  â€¢ {n['title'][:40]}...")
    except Exception as e:
        print(f"æ–°èæ”¶é›†å¤±æ•—: {e}")

    # æ¸¬è©¦æ•´é«”å¸‚å ´æƒ…ç·’
    print("\n3. å¸‚å ´æƒ…ç·’åˆ†æ")
    system = NewsSentimentSystem()
    try:
        result = system.analyze_market_sentiment(limit=10)
        print(f"æ•´é«”æƒ…ç·’: {result['sentiment']}")
        print(f"æƒ…ç·’åˆ†æ•¸: {result['overall_score']:.2f}")
        print(f"ä¿¡å¿ƒåº¦: {result['confidence']:.2f}")
        print(f"ç†±é–€é—œéµè©: {result.get('keywords', [])[:5]}")
    except Exception as e:
        print(f"å¸‚å ´æƒ…ç·’åˆ†æå¤±æ•—: {e}")

    # æ¸¬è©¦æƒ…ç·’ä¿¡è™Ÿ
    print("\n4. äº¤æ˜“æƒ…ç·’ä¿¡è™Ÿ")
    try:
        signal = system.get_sentiment_signal()
        print(f"ä¿¡è™Ÿ: {signal['signal']}")
        print(f"å¼·åº¦: {signal['strength']:.2f}")
        print(f"æè¿°: {signal['description']}")
    except Exception as e:
        print(f"æƒ…ç·’ä¿¡è™Ÿç²å–å¤±æ•—: {e}")
